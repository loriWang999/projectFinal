# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
browser()
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
cl_train <- as.vector(data_train['y'])
class_predict <- knn(train = data_train, test = data_test, cl =  cl_train, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
View(cl_train)
length(cl_train)
length(data_train)
nrow(data_train)
knitr::opts_chunk$set(echo = TRUE)
my_knn_cv <- function(train, cl, k_nn, k_cv){
n <- nrow(train)
inds <- sample(rep(1:k_cv, length = n))
cv_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#splits the data and true species into training and testing sets
data_train <- train[inds != i,]
data_test <- train[inds == i,]
cl_train <- cl[inds != i]
cl_test <- cl[inds == i]
class_output <- knn(train = data_train,
test = data_test,
cl = cl_train, k = k_nn)
#records errors of the predictions
cv_err[i] <- sum(class_output != cl_test)/length(cl_test)
}
output <- knn(train = train, test = train, cl = cl, k = k_nn)
train_err <- sum(output != cl)/length(cl)
my_output <- list(class_output, mean(cv_err), train_err)
return(my_output)
}
my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
my_knn_cv <- function(train, cl, k_nn, k_cv){
browser()
n <- nrow(train)
inds <- sample(rep(1:k_cv, length = n))
cv_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#splits the data and true species into training and testing sets
data_train <- train[inds != i,]
data_test <- train[inds == i,]
cl_train <- cl[inds != i]
cl_test <- cl[inds == i]
class_output <- knn(train = data_train,
test = data_test,
cl = cl_train, k = k_nn)
#records errors of the predictions
cv_err[i] <- sum(class_output != cl_test)/length(cl_test)
}
output <- knn(train = train, test = train, cl = cl, k = k_nn)
train_err <- sum(output != cl)/length(cl)
my_output <- list(class_output, mean(cv_err), train_err)
return(my_output)
}
my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
browser()
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
#cl_train <- as.vector(data_train['y'])
class_predict <- knn(train = data_train, test = data_test, cl =  data_train, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
#cl_train <- as.vector(data_train['y'])
class_predict <- knn(train = data_train, test = data_test, cl =  data_train, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
#cl_train <- as.vector(data_train['y'])
class_predict <- knn(train = data_train, test = data_test, cl =  data_train$y, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
cl_train <- as.vector(data_train['y'])
class_predict <- knn(train = data_train, test = data_test, cl =  cl_train, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
knitr::opts_chunk$set(echo = TRUE)
plot(pressure)
my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
my_knn_cv <- function(train, cl, k_nn, k_cv) {
# generates an error if k_nn or k_cv is not numeric
if(!is.numeric(k_nn) | !is.numeric(k_cv)) {
stop("k_nn and k_cv must be numeric")
}
# length of input data
n <- nrow(train)
# randomly assigns observations to folds 1,…,k with equal probability
fold <- sample(rep(1:k_cv, length = n))
train <- train %>% mutate(fold = fold)
# randomly assigns observations of true class value with folds
cl <- tibble("class" = cl, "fold" = fold)
# output that records predicted class and average misclassification rate
output <- list("class" = NA, "cv_error" = NA)
# cv_error vector that records misclassification rate
cv_error <- rep(NA, k_cv)
# loop through the fold
for (i in 1:k_cv) {
# get the training data
data_train <- train %>% filter(fold != i) %>% select(-contains("fold"))
# get the test data
data_test <- train %>% filter(fold == i) %>% select(-contains("fold"))
# get the true class value of training data
cl_train <- cl %>% filter(fold != i) %>% select(-contains("fold"))
# get the true class value of test data
cl_test <- cl %>% filter(fold == i) %>% select(-contains("fold"))
# predict the class for test data
prediction <- knn(train = data_train, test = data_test, cl = cl_train$class,
k = k_nn)
# caculate the proportions of incorrect predictions by comparing predictions
# to the true class value
cv_error[i] <- (sum(as.vector(prediction) != cl_test)) / nrow(cl_test)
}
# training the model with the full data
output$class <- knn(train = train, test = train, cl = cl$class, k = k_nn)
# average misclassification rate
# round the number to 4 decimals
output$cv_error <- round(mean(cv_error), 4)
return(output)
}
my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
my_knn_cv <- function(train, cl, k_nn, k_cv) {
browser()
# generates an error if k_nn or k_cv is not numeric
if(!is.numeric(k_nn) | !is.numeric(k_cv)) {
stop("k_nn and k_cv must be numeric")
}
# length of input data
n <- nrow(train)
# randomly assigns observations to folds 1,…,k with equal probability
fold <- sample(rep(1:k_cv, length = n))
train <- train %>% mutate(fold = fold)
# randomly assigns observations of true class value with folds
cl <- tibble("class" = cl, "fold" = fold)
# output that records predicted class and average misclassification rate
output <- list("class" = NA, "cv_error" = NA)
# cv_error vector that records misclassification rate
cv_error <- rep(NA, k_cv)
# loop through the fold
for (i in 1:k_cv) {
# get the training data
data_train <- train %>% filter(fold != i) %>% select(-contains("fold"))
# get the test data
data_test <- train %>% filter(fold == i) %>% select(-contains("fold"))
# get the true class value of training data
cl_train <- cl %>% filter(fold != i) %>% select(-contains("fold"))
# get the true class value of test data
cl_test <- cl %>% filter(fold == i) %>% select(-contains("fold"))
# predict the class for test data
prediction <- knn(train = data_train, test = data_test, cl = cl_train$class,
k = k_nn)
# caculate the proportions of incorrect predictions by comparing predictions
# to the true class value
cv_error[i] <- (sum(as.vector(prediction) != cl_test)) / nrow(cl_test)
}
# training the model with the full data
output$class <- knn(train = train, test = train, cl = cl$class, k = k_nn)
# average misclassification rate
# round the number to 4 decimals
output$cv_error <- round(mean(cv_error), 4)
return(output)
}
my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
View(cl_train)
View(cl)
View(cl_train)
View(cl_train)
cl_train$class
length(cl_train(class))
length(cl_train$class)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
class_predict <- knn(train = data_train, test = data_test, cl =  cl_train, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
class_predict <- knn(train = data_train, test = data_test, cl =  data_train$y, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
browser()
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
class_predict <- knn(train = data_train, test = data_test, cl =  data_train$y, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
length(data_train$y)
View(data_train)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
browser()
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
class_predict <- knn(train = data_train, test = data_test, cl =  data_train$y, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Function: my_knn_cv, use this function to predict the species with k nearest neighbors
# Input: train: input data frame
#        cl: true class value of your training data
#        k_nn: integer representing the number of neighbors
#        k_cv: integer representing the number of folds
# Output: a list with
#         class: a vector of the predicted class Yhat_i for all observations
#         cv_err: a numeric with the cross-validation misclassification error
my_knn_cv <- function(train, cl, k_nn, k_cv) {
n <- nrow(train)
# To randomly assigns observations and true class values to folds 1,…,k with equal probability
folds <- sample(rep(1:k_cv, length = n))
train <- data.frame("x" = train, "y" = cl, "split" = folds)
# remove NAs in the data frame
train <- na.omit(train)
# To record the misclassification rate of each iteration
predict_err <- rep(NA, k_cv)
for (i in 1:k_cv) {
#split data frame into training and test data
data_train <- train %>% filter (split != i)
data_test <- train %>% filter (split == i)
# Using knn() to predict ith folder using all other folds as the     training data.
class_predict <- knn(train = data_train, test = data_test, cl =  data_train$y, k = k_nn)
# The rate of the misclassification
predict_err[i] <- sum(class_predict != cl_test)/nrow(cl_test)
}
# store class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# average misclassification rate from my cross validation.
cv_err <- mean(predict_err)
# return a list with class and cv_err
return(list(class, cv_err))
}
test <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
gtwd()
install.packages(c("devtools", "roxygen2", "testthat", "knitr", "covr"))
install.packages(c("devtools", "roxygen2", "testthat", "knitr", "covr"))
getwd()
setwd("/Users/apple/Desktop/STAT302/projects/project_3/project-final")
setwd("/Users/apple/Desktop/STAT302/projects/project_3/project_final")
getwd()
devtools::create("project_final")
devtools::create("projectFinal")
